# # unset HSA_OVERRIDE_GFX_VERSION
# import torch
# import sys
# import os

# print("========== í™˜ê²½ ì§„ë‹¨ ì‹œì‘ ==========")
# print(f"Python Version: {sys.version.split()[0]}")
# print(f"PyTorch Version: {torch.__version__}")

# # í•µì‹¬: ìš°ë¦¬ê°€ ì„¤ì •í•œ í™˜ê²½ ë³€ìˆ˜ê°€ ì˜ ë“¤ì–´ê°”ëŠ”ì§€ í™•ì¸
# print(f"\n[í™˜ê²½ ë³€ìˆ˜ í™•ì¸]")
# print(f"HSA_OVERRIDE_GFX_VERSION: {os.environ.get('HSA_OVERRIDE_GFX_VERSION', 'ì„¤ì •ì•ˆë¨(Not Set)')}")
# print(f"ROCM_PATH: {os.environ.get('ROCM_PATH', 'ì„¤ì •ì•ˆë¨(Not Set)')}")

# print(f"\n[GPU ì—°ê²° í…ŒìŠ¤íŠ¸]")
# try:
#     # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
#     is_available = torch.cuda.is_available()
#     print(f"torch.cuda.is_available(): {is_available}")

#     if is_available:
#         print(f"Make/Model: {torch.cuda.get_device_name(0)}")
#         print(f"Device Count: {torch.cuda.device_count()}")
        
#         # ì‹¤ì œ í…ì„œ ì—°ì‚° í…ŒìŠ¤íŠ¸ (ë©”ëª¨ë¦¬ì— ì˜¬ë¦¬ê¸°)
#         x = torch.tensor([1.0, 2.0, 3.0]).cuda()
#         print(f"Tensor Test: ì„±ê³µ! (ê°’: {x})")
#     else:
#         print("âŒ ì‹¤íŒ¨: GPUë¥¼ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
# except Exception as e:
#     print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")

# print("====================================")


# import os
# from dotenv import load_dotenv
# from langchain_google_genai import ChatGoogleGenerativeAI

# # 1. í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# load_dotenv()

# def test_gemini_connection():
#     print("Checking Google API connection...")
    
#     api_key = os.getenv("GOOGLE_API_KEY")
#     if not api_key:
#         print("âŒ Error: GOOGLE_API_KEY not found in .env file")
#         return

#     try:
#         # 2. ëª¨ë¸ ì´ˆê¸°í™” (ê°€ë²¼ìš´ Flash ëª¨ë¸ ì‚¬ìš©)
#         llm = ChatGoogleGenerativeAI(
#             model="gemini-2.5-flash",
#             temperature=0
#         )
        
#         # 3. ê°„ë‹¨í•œ ì§ˆë¬¸ ì „ì†¡
#         print("Sending request to Gemini...")
#         response = llm.invoke("Hello! Are you working?")
        
#         # 4. ê²°ê³¼ ì¶œë ¥
#         print("\nâœ… Success! Gemini Response:")
#         print(f"Content: {response.content}")
        
#     except Exception as e:
#         print(f"\nâŒ Connection Failed: {e}")

# if __name__ == "__main__":
#     test_gemini_connection()

import os
import sys
import time
import pandas as pd
from tabulate import tabulate # pip install tabulate í•„ìš” (ì—†ìœ¼ë©´ printë¡œ ëŒ€ì²´ ê°€ëŠ¥)

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from src.inference import RAGEngine
from config import BM25_INDEX_PATH

def print_separator(title):
    print(f"\n{'='*20} [ {title} ] {'='*20}")

def debug_retrieval_system():
    print_separator("1. ì‹œìŠ¤í…œ ì´ˆê¸°í™” ìƒíƒœ ì ê²€")
    
    # 1. BM25 ì¸ë±ìŠ¤ íŒŒì¼ í™•ì¸
    if os.path.exists(BM25_INDEX_PATH):
        print(f"âœ… BM25 ì¸ë±ìŠ¤ ë°œê²¬: {BM25_INDEX_PATH}")
        size_mb = os.path.getsize(BM25_INDEX_PATH) / (1024 * 1024)
        print(f"   - í¬ê¸°: {size_mb:.2f} MB")
    else:
        print(f"âŒ BM25 ì¸ë±ìŠ¤ ì—†ìŒ: {BM25_INDEX_PATH}")
        print("   -> Hybrid Searchê°€ ì‘ë™í•˜ì§€ ì•Šê³  Vector Searchë§Œ ìˆ˜í–‰ë©ë‹ˆë‹¤.")
        print("   -> í•´ê²°: 'python pipeline.py' ë˜ëŠ” UIì—ì„œ DB í•™ìŠµì„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")

    # 2. ì—”ì§„ ë¡œë“œ
    print("\n[Engine] RAGEngine ë¡œë”© ì¤‘...")
    start_time = time.time()
    try:
        rag = RAGEngine()
        print(f"âœ… ì—”ì§„ ë¡œë“œ ì™„ë£Œ ({time.time() - start_time:.2f}ì´ˆ)")
    except Exception as e:
        print(f"âŒ ì—”ì§„ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 3. ê²€ìƒ‰ í’ˆì§ˆ í…ŒìŠ¤íŠ¸
    print_separator("2. Hybrid Search & Reranking ìƒì„¸ ë””ë²„ê¹…")
    
    test_query = "ì‚¼ì„±ì „ìì˜ 2024ë…„ ì£¼ìš” ê²½ì˜ ì „ëµì€ ë¬´ì—‡ì¸ê°€?" # ì‹¤ì œ ë°ì´í„°ì— ë§ëŠ” ì§ˆë¬¸ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥
    print(f"ğŸ” í…ŒìŠ¤íŠ¸ ì§ˆë¬¸: \"{test_query}\"")

    try:
        # RAGEngine.search() í˜¸ì¶œ (k=5ë¡œ ë„‰ë„‰í•˜ê²Œ í™•ì¸)
        retrieved_docs = rag.search(test_query, k=5)
        
        if not retrieved_docs:
            print("âŒ ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. (DBê°€ ë¹„ì–´ìˆê±°ë‚˜ í•„í„°ë§ ë¬¸ì œ)")
            return

        # ê²°ê³¼ í…Œì´ë¸” ìƒì„±
        debug_data = []
        for rank, doc in enumerate(retrieved_docs, 1):
            source = os.path.basename(doc.metadata.get('source', 'Unknown'))
            score = doc.metadata.get('rerank_score', 0.0)
            content_preview = doc.page_content[:50].replace('\n', ' ') + "..."
            
            debug_data.append([
                rank, 
                f"{score:.4f}", 
                source, 
                content_preview
            ])

        # ê²°ê³¼ ì¶œë ¥
        headers = ["Rank", "Rerank Score", "Source File", "Content Preview"]
        try:
            print(tabulate(debug_data, headers=headers, tablefmt="grid"))
        except ImportError:
            # tabulateê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì¶œë ¥
            print(f"{'Rank':<5} {'Score':<10} {'Source':<30} {'Content'}")
            for row in debug_data:
                print(f"{row[0]:<5} {row[1]:<10} {row[2]:<30} {row[3]}")

        # ì ìˆ˜ ë¶„ì„
        top_score = retrieved_docs[0].metadata.get('rerank_score', 0)
        if top_score < 0.0: # CrossEncoder ì ìˆ˜ëŠ” ë³´í†µ Logit ê°’ì´ë¯€ë¡œ ìŒìˆ˜ì¼ ìˆ˜ ìˆìŒ (Sigmoid ì „)
             # ëª¨ë¸ì— ë”°ë¼ ë‹¤ë¥´ì§€ë§Œ, ë³´í†µ 0ë³´ë‹¤ í¬ê±°ë‚˜ Sigmoid ì ìš© ì‹œ 0.5 ì´ìƒì´ì–´ì•¼ ê´€ë ¨ì„± ìˆìŒ
             print("\nâš ï¸ [ì£¼ì˜] ìƒìœ„ ë¬¸ì„œì˜ ì ìˆ˜ê°€ ë‚®ìŠµë‹ˆë‹¤. ì§ˆë¬¸ê³¼ ê´€ë ¨ ì—†ëŠ” ë¬¸ì„œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        else:
             print(f"\nâœ… ìƒìœ„ ë¬¸ì„œ ì‹ ë¢°ë„ ì–‘í˜¸ (Top Score: {top_score:.4f})")

    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ë„ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

    # 4. ìƒì„± í…ŒìŠ¤íŠ¸ (ì˜µì…˜)
    print_separator("3. ë‹µë³€ ìƒì„± í…ŒìŠ¤íŠ¸ (Generation)")
    try:
        print("ğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...", end=" ")
        # í‰ê°€ìš© ë™ê¸° ë©”ì„œë“œ ì‚¬ìš©
        answer = rag.generate_answer(test_query)
        print("ì™„ë£Œ!\n")
        print(f"[AI ë‹µë³€]\n{answer}")
    except Exception as e:
        print(f"\nâŒ ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    debug_retrieval_system()